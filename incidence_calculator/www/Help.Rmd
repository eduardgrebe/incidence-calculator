## Analysis of survey data

Once a population level survey has been carried out, the fully specified data set will essentially consist of subject level records indicating demographic factors, cluster/stratum membership, and various clinical indicators such as final HIV status and recency status.

A cross sectional survey leads to a core dataset with typical (germaine to the present application) columns

* Subject ID (a meaningless serial number)
* Primary sampling unit (cluster ID)
* Weight (based on estimates of demographic/geographic structure)
* Stratum (an ID indicating strata such as age, rage, (rural/urban) settlement type,.. )
* Gender/Sex (no need to settle heated debates here - M/F will do)
* HIV status (-/+)
* Recency Status (Non-recent/Recent)

This data will usually be processed by somewhat ad-hoc means, depending on what kind of sampling frame was employed, and what kinds of weights are available. The estimation can be somewhat generalized for certain standard sampling frame types, and there are standard R packages (like *survey*) which can do this. For the present application, the data should be reduced, by whatever means available to the user, to

*	an estimate of HIV prevalence
*	an estimate of the prevalence of ‘recent infection’ amongst those who are HIV positive.
*	A variance/covariance matrix for these two prevalence estimates

While the calculator has no particular requirements or expectations about how these estimates are to be obtained, they need to be provided in the specified format, either by hand into the interface (one survey per transaction of the calculator), or by uploading a file (which makes it possible to provide estimates from multiple surveys in one transaction of the calculator). This choice is made in the top horizontal box of the *Estimate Incidence* tab. Depending on the choice, the page adapts to handle the estimates accordingly. Either way, by using primarily the *inctools* function `incprops`, the calculator will report:

* the (user provided) HIV Prevalence (point estimate and standard error)
* an incidence point estimate and standard error
* the equivalent annualised risk of infection (which is usually numerically very similar)
* the correlation/covariance of HIV Prevalence and Incidence (including an approximate CI ?? REALLY ??)
* implied confidence intervals on MDRI and FRR derived from input parameters provided as PEs and RSEs)


### Entering Survey Results in the Form

Having chosen to enter survey estimates "via a form", there is a further choice, to be made in the *Data type* box, namely whether to supply *estimated prevalences* or *sample counts*.


#### Entering Raw Sample Counts

This option would hopefully be used merely to provide a preliminary analysis.

By *counts* we here mean providing, in the *Survey Data* box, raw survey counts of

* subjects tested for HIV
* positive results
* recency ascertainments (on a completely random subset of positives)
* 'recent' results

*Design Effects* can optionally be provided if there is some rational basis for choosing particular values. The defaults (values of one) mean the data will be interpreted as two binomial experiments - one to estimate prevalence, and an independent experiment to estimate prevalence of recent infection amongst HIV + subjects.
The preloaded sample counts are:

* 5000 subjects tested for HIV
* 1000 positive results (an unweighted HIV prevalence of 20%, estimated with a standard error of 0.56%)
* 900 recency ascertainments on a completely random 900 of the 1000 positives, leading to 45 'recent' (and hence 855 'non recent') results, for a prevalence of recent infection, amongst HIV positives, of 10%, with a relative standard error of 9%

It is worth changing the recency results to be based on 1000 ascertainments (i.e. 100% coverage) and the number of 'recent' results to 50, thus preserving the estimated prevalence of recency amongst positives, and hence the incidence point estimate. Note the slight improvement in precision this produces in the incidenc estimate.


#### Entering Prevalences Estimated with Sampling Complexities Accounted

Using the same underlying data set that generated the counts just used above, one should ideally take account of sampling complexities and directly obtain (for example by using the R package *survey*)
*	an estimate of HIV prevalence
*	an estimate of the prevalence of ‘recent infection’ amongst those who are HIV positive.
*	A variance/covariance matrix for these two prevalence estimates
which can be entered into the *Survey Data* box when choosing the *Data Type* as *estimated prevalences*

This is preloaded with:
*	an estimated HIV prevalence of 20% with a standard error of 1 percentage point
*	an estimated prevalence of ‘recent infection’ amongst those who are HIV positive, of 5%, with a standard error of 1 percentage point
*	a correlation of 0.1 for these two prevalence estimates

Note the increased standard error, though same point estimate of incidence relative to the calculation based on raw survey counts. This is largely due to increased standard errors in the prevalences, but is also slightly responsive to the reported correlation between the prevalences, which has no analog in the raw counts case.



#### Providing Recency Test Properties

Whether working with raw survey counts or preprocessed prevalence estimates, the form based (not file based) version of the *Calculate Incidence* tab provides a "Recency Test" box for entering the test performance defining parameters. These are preloaded to reflect a recency test with:

* an MDRI of 180 days, estimated with a standard error of 10 days
* an FRR of 0.5%, estimated with a standard error of 0.1 percentage points
* a recency time cut off (T) of 730 (i.e 2 Years) - set on a slider

It is interesting to explore how rapidly precision deteriorates as one increases the FRR and/or it's uncertainty. Leaving survey data fixed, and at suitably small FRR, the point estimate and precision of incidence both scale roughly inversely with MDRI.





### Entering Survey Results Via a File

If one chooses to enter survey estimates "via a file", data from multiple surveys can be analysed in a single calculator transaction, by uploading a CSV file with exactly these columns:

* Year
* Prevalence_percent
* SE_Prevalence
* PropRecent_percent
* SE_PropRecent
* Corr_Prev_PropRecent
* MDRI_days
* SE_MDRI
* FRR_percent
* SE_FRR
* BigT

Note that

* the *upload from file* option does not provide a raw survey counts implementation, and
* the recent infection test properties need to be specified for each row (each survey estimate summary)

An example file can be [downloaded here](example_survey_input.csv), saved to the users storage, and then uploaded into the calculator.

Both the uploaded file and the resulting incidence estiamtes are displayed on the screen, and the results can be downloaded as a CSV file.




### Specifying Number of Bootstrap Iterations

For all calculations, the uncertainty analysis is handled by boostrapping prevalence estimates (of HIV and of recent infection amongst HIV positives) and test property estimates from the estimated gaussian distributions implied by the input parameters supplied. This leads to a more faithful handling of the non linearities in the functional form of the Kassanjee estimator than would be produced by a delta method approach, but naturally does not address any deviations from normality in teh prevalence estimation process - which is expected to be a minor point. The proposed value of 100,000 iterations preloaded into the form leads to high reproducibility of the uncertainty estimates and no significant delays while refreshing the calculator results when inputs are changed. It is worth triggering a refresh of the calculation by changing any parameter back and forth between two values and checking the reproducibility of the standard error estimates, and the prevalence/incidence correlation estimate.
