<!-- # Shiny App to Process Data from a Cross Sectional Survey with HIV status and ‘Recency’ Status Ascertainment, for Joint Estimation of HIV Prevalence and Incidence, Including Covariance. -->

## Introduction

This app is designed to support the estimation of

* HIV prevalence,
* HIV incidence, and
* (crucially) Full variance/covariance of the above

through analysis of cross-sectional surveillance data including biomarkers supporting classification of (HIV) cases as recently or non-recently acquired.

The underlying logic in this prevalence/incidence calculator is core functionality of the R package *inctools*.

While the correct use of the app and the underlying *inctools* package does not require any detailed technical knowledge about the theoretical underpinnings, an understanding of the core concepts will be useful. This document is intended to provide technical background for transparency/reproducibility, and also to help potential users orient themselves.

The *Help* tab/document provides a walk through of the preloaded examples.

Users working to provide national level estimates as part of an interaction with UNAIDS are invited to contact the maintainers for assistance and are indeed requested to provide any notification of possible errors, as well as general feedback about clarity and functionality.


## Overview of Analytical Framework

The critical core of all the functionality of package *inctools*, and hence of this app, is the incidence estimator of *Kassanjee et al* (Epidemiology, 2012) and some hitherto unpublished generalisations to accomodate structured survey design, including incomplete coverage of recency ascertainment. In essence, this generalisation involves the replacement of simple survey counts, assumed in *Kassanjee et al* to be trinomially distributed, by estimated prevalences of: 1) HIV, and 2) ‘recent infection’ amongst HIV positives (including a potential covariance, which does not arise in the trinomial distribution case).

The theoretical basis for this approach to incidence estimation is developed in Kassanjee et al* (Epidemiology, 2012), with considerable detail and nuances spelled out. Key points of the conceptual framework can be captured in the following remarks (A Glossary further below aims to provide some conceptual depth on terminology):

* There is presumed to be some test, which categorises HIV positive individuals as being ‘recent’ or ‘non recent’ cases.
* It does not really matter, logically/mathematically/statistically, how well this test performs. The analysis is valid in any case. It is just a matter of how informative the analysis of the relevant marker will be. Indeed, for real world HIV applications, it is not easy to devise a test that leads to highly precise incidence estimates at feasible sample sizes.
* In particular, the test performance does not, in and of itself, lead to any exposure to *bias* in incidence estimation. However, having a mistaken view of the tests properties can indeed lead to bias. Test performance determines incidence estimate *precision*. In (*Kassanjee et al, AIDS Research and Human Retroviruses, 2014*) this point is further developed to demonstrate that test optimisation is a matter of minimising incidence estimate variance.
* Optimisation of tests (most clearly for tests based on a single marker) involves adjustment of some recent/non-recent discrimination *threshold*. This leads to a trade-off between the Mean Duration of Recent Infection (MDRI) and False Recent Rate (FRR) (see glossary). Increasing the MDRI means a greater (more precisely estimable) number/proportion of recent cases in a cross sectional survey, but this eventually and inevitably comes at the cost of a non trivial FRR, the accounting of which leads to the growth of an additional high-variance term in the estimator.
* It bears pointing out that there is no *gold standard* for a test for recent infection, in anything resembling the meaning of the term that is appropriate for a discussion of usual clinical diagnostics. In particular, there is no natural, or a priori selectable time scale for ‘recent infection’ which a recency test is then aimed at optimally detecting. The case definition for recent infection is, then, essentially defined arbitrarily, by the biomarker, which becomes the gold standard, if one must have one. Of course a definition for recent infection is usefully (statistically) informative, for incidence estimation, only if it captures something usually exhibited by newly infected individuals, and very rarely exhibited by people infected for substantial periods like several years.
* The framework of Kassanjee et al provides an estimate/estimator for a (time) weighted average value of incidence over a period preceding a cross sectional survey in which HIV and recent infection are ascertained. Incidentally, time weighting is also intrinsic to cohort studies, as the effective cohort size varies over the stages of recruitment, maintenance, and completion of follow up. The time averaging implied, when one considers any study design, including cohorts, often turns out to have complex details that are difficult or impossible to determine, and are fortunately usually secondary. In the case of the Kassanjee framework, the sensible heuristic is that the expectation value of the estimator should be understood to be practically indistinguishable from the uniformly weighted incidence over a period of about one MDRI preceding the survey.
* Users of the present tool may decide, given inter-survey intervals and other considerations, whether they choose to assign the prevalence and incidence estimates to the same time point. The first order correction to this would be to assign, to an incidence estimate, a time of one half MDRI before the prevalence estimate from the same survey. For most applications, this is probably not important to account explicitly.
* the original paper in Epidemiology introduces 8 sources of ‘higher order corrections’ beyond the leading order that is captured in the nominal Kassanjee estimator. Most of these are very minor and not worth further analysis here. The one point worthy of some attention is that the usual form of the estimator assumes that the underlying susceptible population is constant. In a cohort, the susceptible population is always decreasing, and it is doing so precisely due to infections accruing, and perhaps loss to follow up. In an open population which is surveyed in a major household survey, it is not obvious whether the susceptible population is in fact increasing or decreasing, as there may be non-trivial migration or ‘aging in’ and ‘aging out’ contributions, in addition to the incidence itself. Some published forms of an estimator to handle recent infection data appear to have adopted a view aligned closely to the cohort situation. These details are all of the flavour of how to optimally handle the estimation of exposure time in a cohort in which follow up is infrequent, and assumptions must be made about the distribution of infection events. This is very much a fine point, however, as the main source of statistical uncertainty arises from the random *number of* infection events. The details of timing, and the consequences for exposure time, are secondary.




## Glossary

The package inctools, and discussion of applications built on the inctools infrastructure, implies use of some common and some specialised (to this sub-field) terms which it may be prudent to define here. These are rendered as conceptual rather than technical definitions.

### HIV infected individual

The protocol-specific case definition for HIV infected individual needs to be very clearly spelled out. This is because there is no universal standard, although there have for some years been variants on protocols involving sensitive screening tests and highly specific “confirmatory” or “supplemental” tests.  Studies may use viral nucleic acid and antigen detection, and not even rely on classical serological ‘confirmation’ of HIV infection. On the other hand, ‘diagnostic delays’ (between acquisition and detectability of infection) of tests for HIV are now probably just a few days away from what they will ever be, so reasonable rough estimates are always obtainable.

### Mean duration of recent infection (MDRI)

The average time for which subjects satisfy a particular “recent infection” case definition, within a specified recency cut-off time T after (detectable) infection. The MDRI is context/protocol specific, but can be estimated from published data with some minor adjustment for HIV screening algorithms.

### False-recent rate (FRR)

The (even more notably context specific than MDRI) fraction of tests, performed on individuals (detectably) infected for more than the time cut-off T, which produce a (false) recent result.  This piece of terminology has seen many variants.  FRR is inspired by the long used term “error rate” to refer to the fraction of tests which fail in some sense.  Note that there is fundamentally no such thing as a *false non-recent result/rate*. Some individuals just happen to transition to the non-recent case definition at relatively early times post-infection. This is a natural example of inter-subject variability, and is accounted for in the definition of MDRI.

### Incidence as a (or, “an instantaneous”) rate

This is the most fundamental metric for expressing the rate at which HIV infections occur in the susceptible (aka “at risk”) population, and is naturally expressed as a number of (infection) events per person time at risk in the referenced susceptible population.  In the case of some other epidemiological contexts (such as influenza) it is not uncommon to refer to person time in the entire population, rather than the susceptible sub-population, although this difference in definition does occasionally cause confusion.  While, in principle, any unit of time may be used (days, weeks, months) the usual unit in HIV discourse is the year.  It is important to note that the value of an incidence rate can in principle take any value, as it changes with choice of units in which time is measured. For contrast, see the next item immediately below.

### Annual(ised) risk of infection

It is also common to report the “cumulative” probability of infection over a specific period of time, such as one year.  It is a subtle point, not worth expositing here in detail, that the instantaneous incidence, with time measured in years, is not, in principle, the same value as the annual risk of infection.  Suffice to 1) repeat what was noted in the preceding glossary item, namely that incidence as a “rate” can in principle attain any value, depending on choice of units of time measurement, and 2) add that, by contrast, the probability of infection cumulated over a particular time period is always a number between zero and one.

### Recency time cut-off T (“Big T”)

On account of the fact that it is always possible (even if quite unlikely) for a recency test to classify some individuals as 'recently infected' at long times post infection, the use of a time cut-off T has been introduced to assist in the mathematical housekeeping.  The details of how this works subte, but if using a recent infection test based on a reasonable body of literature, there is little risk in adopting previously proposed cut off times.

### Relative standard error (RSE)

This widely used term refers to the ratio of a standard error of an estimate to the point estimate.

### Null hypothesis

A usually artificial assumption (not necessarily strongly believed, and perhaps strongly suspected to be false) which data either falsifies or fails to falsify.

### p-value

The probability, calculated under a particular *null hypothesis*, of seeing (at least) a specified deviation of a test-statistic relative to its mean value under the applicable *null hypothesis*.  The classic p-value in this context answers the question: If the incidence were really the same in two populations which have been surveyed, what is the probability of seeing a point estimate of the incidence difference, the absolute value of which is at least as large as the one observed?

### Significance

This widely used term refers to a threshold on a p-value, below which the experimenters will reject a given null hypothesis and declare there to be a “statistically significant” “effect” or “difference”.

### Sample size

The total number of individuals whose HIV status has been, or is proposed to be, assessed.

### Design effect

This parameter captures the impact of complexities in sampling which arise from the fact that individuals surveyed are not independently selected from the total population nominally ‘represented’. These complexities include hierarchical (clustered) sampling, stratification, weighting, etc. A Design effect captures the ratio of the actual variance of a metric (such as a prevalence of some defined condition) to the variance that would be obtained for the same metric if the analysis were conducted on the simplifying assumption that the individuals surveyed have been drawn independently from a large population. A design effect greater than one implies the correctly calculated variance is larger than the naive variance calculated on the assumption of simple independent sampling.

Within *inctools*, there is provision for users to provide scale factors (design effects) adjusting the uncertainty in estimates of

1.	the proportion of HIV infected individuals (i.e. prevalence) and
2.	the proportion of “recent” results among HIV positive individuals (i.e. prevalence of recent infection among HIV positives).

It should be noted that:

*	Design Effects are mainly useful as heuristic estimates to be used when a survey is being designed (i.e. in calculations of power, sample size, etc). Once survey data is in hand, it makes more sense to analyse it by suitably adapted standard methods, to yield estimates, and a variance/covariance matrix, which do not specifically contain a reference to a sample size, and do not require a design effect adjustment. Nevertheless, the prevalence/incidence web app provides some access to underlying inctools uses of design effects.
*	There is no clear consensus on approach, and there are no mature tools, for estimating a priori design effect parameters for population based HIV surveys.
*	The two design effects are logically independent parameters, which capture the effects of two logically independent processes (ascertaining HIV, and ascertain recent infection amongst HIV positive subjects).
*	It is not appropriate to use design effects to scale the variances of the test property (MDRI and FRR) estimates, as these are not estimated in the incidence survey, but rather arise in the recency test development process.

## Release notes

**Version 1.03**: Bootstrap resampling from truncated normal distribution to prevent negative values being drawn for prevalences, MDRI and FRR.
